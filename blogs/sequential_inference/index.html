<!DOCTYPE html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1.0"><title>Virie's weblog</title><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=icon type=image/svg+xml href=../../resources/Virie_symbol_2023.svg><link rel=stylesheet href=../../styles/effect.css><link rel=stylesheet href=../../styles/banner.css><link rel=stylesheet href=../../styles/theme.css><link rel=stylesheet href=../styles/layout.css><link rel=stylesheet href=../styles/theme.css><link rel=stylesheet href=./styles.css></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-45PD6BDYNZ"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-45PD6BDYNZ');
</script><body class=neutral-2><div class="banner active secondary"><div class=title><h1 id=virie-header class=relief></h1></div><div class="menu relief"><a href=../../index.html>home</a><a href=../../weblogs.html>weblogs</a><a href=../../profile.html>profile</a><a href=../../persona.html>persona</a></div></div><div class="navigate tertiary silver-lining-bottom"><a href=../arbitrary_ode/index.html>prev</a><a href=../../weblogs.html class=date>February 15th, 2024</a><a href=../discounted/index.html>next</a></div><div class="blog primary"><div class=content><h1>&#8747 Hidden Markov models: baseline algorithms </h1><hr><div class=kernel><h2> Kernel: </h2><ul><li> A review of baseline algorithms for hidden Markov model inference and learning.</li></ul></div><p class=first> In this blog post, I will review some of the baseline algorithms for hidden Markov model (HMM) inference and learning, Although, there are tons of explanations and tutorials out there, but I find that most of them using inconsistent terminologies and notations. For example, do you know that there are two Viterbi algorithms? And the forward-backward algorithm is sometimes known as the Baum-Welch algorithm? while in the wikipedia these are two different algorithms? This is wild! And hopefully, I can make things clearer. </p><h2>&#8706 Hidden Markov models</h2><div class=hmm> [{ "type": "node", "hidden_state": { "name": "X", "subscript": "1" }, "observation": { "name": "Y", "subscript": "1" } }, { "type": "connector" }, { "type": "node", "hidden_state": { "name": "X", "subscript": "t" }, "observation": { "name": "Y", "subscript": "t" } }, { "type": "node", "hidden_state": { "name": "X", "subscript": "t+1" }, "observation": { "name": "Y", "subscript": "t+1" } },{ "type": "connector" },{ "type": "node", "hidden_state": { "name": "X", "subscript": "T" }, "observation": { "name": "Y", "subscript": "T" } }] </div><p> Hidden Markov models are a class of probabilistic graphical models that are widely used in speech recognition, bioinformatics, and other fields. They are used to model sequences of observations, where the observations are assumed to be generated by a sequence of hidden states. The hidden states are not observed, but the observations are assumed to depend only on the current state, hence the name <a href=https://en.wikipedia.org/wiki/Markov_property>Markov</a>. </p><p> A hidden Markov model is defined by the following parameters: <ul><li>\( X_t \) is a random variable of the hidden state at time \( t \).</li><li>\( Y_t \) is a random variable the observation at time \( t \).</li><li>\( T \) is a positive integer specifying a sequence length. </li><li>\( \Pr(X_{t+1} | X_{t}) \) is a parameter that represents the transition probability from state \( X_t \) to state \( X_{t+1} \).</li><li>\( \Pr(Y_t | X_t) \) is a parameter that represents the observation probability of observation \( Y_t \) given state \( X_t \).</li></ul></p><div class=kernel> \( \Pr(X) \) is a short form of \( \Pr(X=x) \), the probability of \( X \) taking the value \( x \) whatever \( x \) is. </div><p> In general, there are four types of problems that we want to solve with hidden Markov models: <ol><li>Given HMM parameters, sample some observations.</li><li>Given a sequence of observations and HMM parameters, what is the most likely sequence of hidden states that generated the observations? This is known as the decoding problem.</li><li>Given a sequence of observations and HMM parameters, what is the probability of a sequence of observations? This is known as the evaluation problem.</li><li>Given a sequence of observations, how can we learn the parameters of the model? This is known as the learning problem.</li></ol> The sampling problem is relatively straightforward given the model's parameters, but the other problems are not. Fortunately, HMMs have been around for decades and there are many algorithms to solve these problems: </p><h2>&#8706 Forward algorithm</h2><p> The forward algorithm is used to solve the evaluation problem of the latest hidden state given the sequence of observations so far. </p><div class=mathjax> $$ \begin{align*} \arg\max_{X_t} \, \Pr(X_t | Y_{1:t}) \end{align*} $$ </div><p> One nice thing about inference algorithms in HMM is that they can usually be arranged in a recursive form. The recursive form of the forward algorithm is as follows: </p><div id=eq:forward class=mathjax> $$ \begin{align*} f(X_t) &= \Pr(X_t , Y_{1:t}) \\ &= \Pr(X_t, Y_t, Y_{1:t-1}) \\ &= \Pr(Y_t| X_t, Y_{1:t-1}) \Pr(X_t, Y_{1:t-1}) \\ &= \Pr(Y_t| X_t) \Pr(X_t, Y_{1:t-1}) \\ &= \Pr(Y_t | X_t) \sum_{X_{t-1}} \Pr(X_t, X_{t-1}, Y_{1:t-1}) \\ &= \Pr(Y_t | X_t) \sum_{X_{t-1}} \Pr(X_t | X_{t-1}, Y_{1:t-1}) \Pr(X_{t-1}, Y_{1:t-1}) \\ &= \Pr(Y_t | X_t) \sum_{X_{t-1}} \Pr(X_t | X_{t-1}) \Pr(X_{t-1}, Y_{1:t-1}) \\ &= \Pr(Y_t | X_t) \sum_{X_{t-1}} \Pr(X_t | X_{t-1}) f(X_{t-1}) \tag{1} \\ \end{align*} $$ </div><p> Then in order to solve the evaluation problem, we can use the following equation: </p><div class=mathjax> $$ \begin{align*} \max_{X_t} \, \Pr(X_t | Y_{1:t}) &= \max_{X_t} \, \frac{\Pr(X_t, Y_{1:t})}{\Pr(Y_{1:t})} \\ &= \eta \max_{X_t} \Pr(X_t, Y_{1:t}) \\ &= \eta \max_{X_t} f(X_t) \\ \end{align*} $$ </div><div class=kernel> \( \eta \) is a normalizing constant that makes the probability sum to 1. When you are computing maximum, you can safely ignore it. </div><p> Because of this property, the forward algorithm can be used to solve the evaluation problems where we want to know the most likely state at the current time given the sequence of observations so far. We often find the use for this algorithm in realtime inference tasks<span class=cite>Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.</span><span class=cite>Welch, G., & Bishop, G. (1995). An introduction to the Kalman filter.</span><span class=cite>Djuric, P. M., Kotecha, J. H., Zhang, J., Huang, Y., Ghirmai, T., Bugallo, M. F., & Miguez, J. (2003). Particle filtering. IEEE signal processing magazine, 20(5), 19-38.</span>. </p><h2>&#8706 Forward-backward algorithm</h2><p> What if you want to solve the evaluation problem of the hidden state at any time given the sequence of observations so far, for the benefit of hindsight? This is where the forward-backward algorithm comes in. </p><div class=mathjax> $$ \begin{align*} \Pr(X_t | Y_{1:T}) &= \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t | Y_{1:t})}{\Pr(Y_{t+1:T} | Y_{1:t})} \\ \end{align*} $$ </div><p> The forward-backward algorithm has two folds: the forward pass and the backward pass. The forward pass is the same as the forward algorithm. Let me show you how the backward pass is computed: </p><div id=eq:backward class=mathjax> $$ \begin{align*} b(X_t) &= \Pr(Y_{t+1:T}| X_t) \\ &= \sum_{X_t+1} \Pr(Y_{t+1:T}, X_{t+1}| X_t) \\ &= \sum_{X_t+1} \Pr(Y_{t+2:T}, X_{t+1}, Y_{t+1}| X_t) \\ &= \sum_{X_t+1} \Pr(Y_{t+2:T}| X_{t+1}, Y_{t+1}, X_t) \Pr(X_{t+1}, Y_{t+1}| X_t) \\ &= \sum_{X_t+1} \Pr(Y_{t+2:T}| X_{t+1}) \Pr(X_{t+1}, Y_{t+1}| X_t) \\ &= \sum_{X_t+1} b(X_{t+1}) \Pr(X_{t+1}, Y_{t+1}| X_t) \\ &= \sum_{X_t+1} b(X_{t+1}) \Pr(Y_{t+1}| X_{t+1}, X_t) \Pr(X_{t+1}| X_t) \\ &= \sum_{X_t+1} b(X_{t+1}) \Pr(Y_{t+1}| X_{t+1}) \Pr(X_{t+1}| X_t) \tag{3} \\ \end{align*} $$ </div><p> Now we combine the forward and backward passes to solve the evaluation problem of the hidden state at any time given the sequence of observations so far. </p><div class=mathjax> $$ \begin{align*} \max_{X_t} \, \Pr( X_t| Y_{1:T}) &= \max_{X_t} \, \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t | Y_{1:t})}{\Pr(Y_{t+1:T} | Y_{1:t})} \\ &= \mu \max_{X_t} \, \Pr(Y_{t+1:T} | X_t) \Pr(X_t | Y_{1:t}) \\ &= \mu \max_{X_t} \, \Pr(Y_{t+1:T} | X_t) \eta \Pr(X_t, Y_{1:t}) \\ &= \mu \eta \max_{X_t} \, b(X_t) f(X_t) \\ \end{align*} $$ </div><div class=kernel> \( \mu \) and \( \eta \) are normalizing factors as before. </div><p> If you want to compute the probability, you can use the following equation: </p><div class=mathjax> $$ \begin{align*} \Pr( X_t | Y_{1:T}) &= \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t | Y_{1:t})}{\Pr(Y_{t+1:T} | Y_{1:t})} \\ &= \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t, Y_{1:t})}{\Pr(Y_{t+1:T}, Y_{1:t})} \\ &= \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t, Y_{1:t})}{\sum_{X_t} \Pr(Y_{t+1:T}, X_t, Y_{1:t})} \\ &= \frac{\Pr(Y_{t+1:T} | X_t) \Pr(X_t, Y_{1:t})}{\sum_{X_t} \Pr(Y_{t+1:T} | X_t)\Pr(X_t | Y_{1:t})} \\ &= \frac {b(X_t) f(X_t)}{\sum_{X_t} b(X_t) f(X_t)} \\ \end{align*} $$ </div><h2>&#8706 Viterbi algorithm</h2><p> Next stop is the Viterbi algorithm. We use to solve the decoding problem of the most likely sequence of hidden states given the sequence of observations. </p><div class=mathjax> $$ \begin{align*} \arg\max_{X_{1:t}} \, \Pr( X_{1:t}| Y_{1:t}) \end{align*} $$ </div><p> Same as the forward algorithm, the Viterbi algorithm can be arranged in a recursive form: </p><div id=eq:viterbi class=mathjax> $$ \begin{align*} v(X_t) &= \max_{X_{1:t-1}} \, \Pr(X_{1:t}, Y_{1:t}) \\ &= \max_{X_{1:t-1}} \, \Pr( X_t, Y_t | X_{1:t-1}, Y_{1:t-1}) \Pr( X_{1:t-1}, Y_{1:t-1}) \\ &= \max_{X_{1:t-1}} \, \Pr( Y_t | X_t) \Pr( X_t | X_{1:t-1}, Y_{1:t-1}) \Pr( X_{1:t-1}, Y_{1:t-1}) \\ &= \max_{X_{1:t-1}} \, \Pr( Y_t | X_t) \Pr( X_t | X_{t-1}) \Pr( X_{1:t-1}, Y_{1:t-1}) \\ &= \Pr( Y_t | X_t) \max_{X_{1:t-1}} \, \Pr( X_t | X_{t-1}) \Pr( X_{1:t-1}, Y_{1:t-1}) \\ &= \Pr( Y_t | X_t) \max_{X_{t-1}} \, \Pr( X_t | X_{t-1}) \max_{X_{1:t-2}} \, \Pr( X_{1:t-1}, Y_{1:t-1}) \\ &= \Pr( Y_t | X_t) \max_{X_{t-1}} \, \Pr( X_t | X_{t-1}) v(X_{t-1}) \tag{2} \\ \end{align*} $$ </div><p> Then in order to solve the decoding problem, we can use the following equation: </p><div class=mathjax> $$ \begin{align*} \max_{X_{1:t}} \, \Pr( X_{1:t}| Y_{1:t}) &= \max_{X_{1:t}} \, \frac{\Pr( X_{1:t}, Y_{1:t})}{\Pr(Y_{1:t})} \\ &= \eta \max_{X_{1:t}} \Pr( X_{1:t}, Y_{1:t}) \\ &= \eta \max_{X_t} \, \max_{X_{1:t-1}} \, \Pr(X_{1:t}, Y_{1:t}) \\ &= \eta \max_{X_t} \, v(X_t) \end{align*} $$ </div><p> You may notice that the Viterbi algorithm is very similar to the forward algorithm, but instead of summing over all possible previous states, we take the maximum over all possible previous states. The similarity is not a coincidence. It depends on the way we choose to arrange the probability terms by pulling out the time \( t \) terms first, similar to the way we did in the forward algorithm. (If you want to challenge yourself, try to solve the decoding problem backward and see what you come up with.) </p><div class=kernel> The Viterbi algorithm is a special case of the max sum algorithm for graphical models.<span class=cite>Koller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press.</span></div><h2>&#8706 Viterbi <i>training</i> algorithm</h2><p> Do not confuse this with the Viterbi <i>decoding</i> algorithm. The Viterbi training algorithm is a training algorithm for hidden Markov model where the goal is to learn the parameters of the model given sequences of observations. </p><div class=mathjax> $$ \begin{align*} \arg\max_{\theta} \, \Pr(Y_{1:T} | \theta) \end{align*} $$ </div> \( \theta \) is the set of parameters of the model, which includes the transition probability and the observation probability. <p> The Viterbi training algorithm uses the Viterbi decoding algorithm to find the most likely sequence of states, and then uses it to update the parameters of the model. It's a special case of the Expectation-Maximization (EM) algorithm<span class=cite>Bishop, C. (2006). Pattern recognition and machine learning. Springer google schola, 2, 5-43.</span>, which has to be run iteratively until the parameters converge. </p><ol><li>Compute the most likely sequence of states using the Viterbi algorithm.</li><li>Update the observation parameters <div class=mathjax> $$ \begin{align*} \Pr(Y=y | X=x) = \frac{\text{frequency of observing both} \, y \, \text{and} \, x \, \text{from all steps}}{\text{frequency of} \, x \, \text{from all steps in the sequence}} \end{align*} $$ </div><li>Update the transition parameters <div class=mathjax> $$ \begin{align*} \forall t \, \Pr(X_{t+1 }= x' | X_{t} = x) = \frac{\text{frequency of} \, x \, \text{then} \, x' \, \text{from all steps}}{\text{frequency of} \, x \, \text{from all steps in the sequence}} \end{align*} $$ </div></li><li>Repeat until the parameters converge. </ol><div class=kernel> Note that both the observation and the transition parameters are shared across all time steps. </div><h2>&#8706 Baum-Welch algorithm</h2><p> This is another training algorithm for hidden Markov model. It uses the forward-backward algorithm to update the parameters of the model instead of relying on statistical counting. In practice, this is more stable than the Viterbi training algorithm<span class=cite>Lam, T. Y., & Meyer, I. M. (2010). Efficient algorithms for training the parameters of hidden Markov models using stochastic expectation maximization (EM) training and Viterbi training. Algorithms for Molecular Biology, 5, 1-16.</span>. </p><div class=mathjax> $$ \begin{align*} \Pr(Y | X) &= \frac{\sum_t \Pr(Y_t, X_t)}{\sum_t \Pr(X_t)} \\ &= \frac{\sum_t \sum_{Y_{1:T} \setminus Y_{t}} \Pr(X_t, Y_{1:T})}{\sum_t \sum_{Y_{1:T}} \Pr(X_t, Y_{1:T})} \\ &= \frac{\sum_t \Pr(Y_t) \sum_{Y_{1:T} \setminus Y_{t}} \Pr(Y_{1:T} \setminus Y_{t} | Y_{t}) \Pr(X_t | Y_{1:T})}{\sum_t \sum_{Y_{1:T}}\Pr(Y_{1:T}) \Pr(X_t| Y_{1:T})} \\ \end{align*} $$ </div><div class=kernel><ul><li>\( Y_{1:T} \setminus Y_{t} \) means the sequence of all observations except \( Y_t \).</li><li>If you see this form \( \sum_{A} P(A) K \), it means that we are compute the expectation of \( K \) following the distribution of \( A \). If \( A = Y_{1:T} \), it's the distribution of the observed sequences.</li></ul></div><div class=mathjax> $$ \begin{align*} \forall t \, \Pr(X_{t+1} | X_{t}) &= \frac{\sum_t \Pr(X_{t+1}, X_t)}{\sum_t \Pr(X_t)} \\ &= \frac{\sum_t \sum_{Y_{1:T}} \Pr(X_{t+1}, X_t, Y_{1:T})}{\sum_t \Pr(X_t)} \end{align*} $$ </div> The term \( \Pr(X_{t+1}, X_t, Y_{1:T}) \), or the \( \xi \) conventionally, can be expanded as follows: <div id=eq:4 class=mathjax> $$ \begin{align*} \Pr(X_{t+1}, X_t, Y_{1:T}) &= \Pr(X_{t+1}, Y_{1:T}| X_t) \Pr(X_t) \\ &= \Pr(X_{t+1}, Y_{t+1:T}, Y_{1:t}| X_t) \Pr(X_t) \\ &= \Pr(X_{t+1}, Y_{t+1:T} | X_t) \Pr(Y_{1:t} | X_t) \Pr(X_t) \\ &= \Pr(X_{t+1}, Y_{t+1:T} | X_t) f(X_t) \\ &= \Pr(Y_{t+1}, X_{t+1}, Y_{t+2:T} | X_t) f(X_t) \\ &= \Pr(Y_{t+1} | X_{t+1}) \Pr(X_{t+1}, Y_{t+2:T} | X_t) f(X_t) \\ &= \Pr(Y_{t+1} | X_{t+1}) \Pr(Y_{t+2:T} | X_{t+1}) \Pr(X_{t+1} | X_t) f(X_t) \\ &= {\color{red}\Pr(Y_{t+1} | X_{t+1})} b(X_{t+1}) {\color{blue}\Pr(X_{t+1} | X_t)} f(X_t) \tag{4} \\ \end{align*} $$ </div><p> This is the original Baum-Welch algorithm. Notice that equation <a href=#eq:4>(4)</a> reuses the current parameters of the model to compute the expected statistics. And we run this iteratively until the parameters converge. </p><div class=kernel><p> One might wonder can't we simplify the equation like this: </p><div class=mathjax> $$ \begin{align*} \forall t \, \Pr(X_{t+1}| X_{t}) &= \frac{\sum_t \Pr(X_{t+1}, X_t)}{\sum_t \Pr(X_t)} \\ &= \frac{\sum_t \Pr(X_{t+1}| X_t) \sum_{Y_{1:T}} \Pr(X_t, Y_{1:T})}{\sum_t \Pr(X_t)} \\ &= \frac{\sum_t \Pr(X_{t+1}| X_t) \sum_{Y_{1:T}} \Pr(Y_{1:T}) \Pr(X_t| Y_{1:T})}{\sum_t \Pr(X_t)} \end{align*} $$ </div><p> This simplified version uses only the forward-backward algorithm at each time \(t\) while the original Baum-Welch algorithm uses pincer estimation of both \(X_{t+1}\) from the backward path <a href=#eq:backward>(3)</a>, and \(X_t\) from the forward path <a href=#eq:forward>(1)</a>, bridge by the current transition probability and the observation probability <a href=#eq:4>(4)</a>. </p><p> However, this derivation will not work! Because it's the exact equation! The principle of Expectation-Maximization is to compute first the expectation of the estimated statistics given the current parameters. The estimated statistics in this case are 1) \( \Pr(Y_{t} | X_{t}) \) and 2) \(\Pr(X_{t+1}| X_t, Y_{1:T})\) which are computed inside the Baum-Welch algorithm but not in the simplified version. </p></div><h2>&#8706 Conclusion</h2><p> To recap, we have reviewed some of the baseline algorithms for hidden Markov model inference and learning. </p><div class=flexible><table><thead><tr class=tertiary><th>Algorithm</th><th>Problem</th><th>Objective</th></tr></thead><tbody><tr class=neutral><td>Forward</td><td>Evaluate the most likely state at the current time given the sequence of observations so far.</td><td>\( \arg\max_{X_t} \, \Pr(X_t | Y_{1:t}) \)</td></tr><tr><td>Forward-backward</td><td>Evaluate the most likely state at any time given the sequence of observations so far.</td><td>\( \arg\max_{X_t} \, \Pr(X_t | Y_{1:T}) \)</td></tr><tr class=neutral><td>Viterbi</td><td>Decode the most likely sequence of hidden states given the sequence of observations.</td><td>\( \arg\max_{X_{1:t}} \, \Pr( X_{1:t}| Y_{1:t}) \)</td></tr><tr><td>Viterbi training</td><td>Learn the parameters of the model given sequences of observations.</td><td>\( \arg\max_{\theta} \, \Pr(Y_{1:T} | \theta) \)</td></tr><tr class=neutral><td>Baum-Welch</td><td>Learn the parameters of the model given sequences of observations.</td><td>\( \arg\max_{\theta} \, \Pr(Y_{1:T} | \theta) \)</td></tr></tbody></table></div><p> That is it! These are important algorithms for hidden Markov models that we should know! </p><hr><ul class=bibliography></ul></div></div><script src=../../libs/svg.min.js></script><script src=../scripts/bibliography.js></script><script src=./hmm.js></script><script src=../../scripts/viewer.js></script><script src=../../scripts/active.js></script><script src=../scripts/weblog.js></script></body></html>